# Relat√≥rio T√©cnico v4.5: LLM Router Inteligente e Gest√£o de Propostas

**Sistema "Segundo C√©rebro" da C4 Marketing ‚Äî 17 de Fevereiro de 2026**

A vers√£o 4.5 resolve a fragilidade fundamental do sistema de roteamento: **o agente dependia de listas de palavras-chave hardcoded** para decidir qual consulta executar. Agora ele usa **GPT-4o-mini com Function Calling** para entender o contexto sem√¢ntico de qualquer pergunta em linguagem natural. Al√©m disso, propostas aceitas s√£o separadas das abertas em toda a stack.

---

## Linha do Tempo da Evolu√ß√£o

| Vers√£o | Nome | Capacidade Principal |
|--------|------|---------------------|
| v1 | Chat RAG | Busca vetorial + filtro anti-eco |
| v2 | Agentic RAG | Router heur√≠stico, 6 Agentes, ETL autom√°tico |
| v3 | Hybrid Intelligence | Tool Use (RAG + SQL direto) |
| v4.1 | Cognitive Agent | Identidade + Mem√≥ria de Sess√£o + Cobertura Total |
| **v4.5** | **Semantic Router** | **LLM Router (Function Calling) + Gest√£o de Propostas** |

---

## Mudan√ßa Arquitetural Principal: De Keywords para Sem√¢ntica

### O Problema (v2‚Äìv4.1)

O roteamento do sistema dependia de **listas de palavras-chave fixas** para decidir qual ferramenta usar:

```typescript
// ‚ùå Abordagem antiga (heur√≠stica)
if (hasAny(msg, ["aberta", "pendente", "aguardando"])) {
    statusFilter = 'open'  // ‚Üê e se o usu√°rio disser "em aberto"?
}
```

Isso gerava falhas reais:

- **"quais propostas est√£o em aberto?"** ‚Üí Palavra "aberto" n√£o matchava com "aberta" ‚Üí resposta errada
- **"quais propostas..."** ‚Üí "quais" sozinho n√£o era keyword de listagem ‚Üí ca√≠a no RAG gen√©rico
- **"tem tarefa pendente?"** ‚Üí Sem "liste" ou "todos", n√£o era detectado como listagem

Cada erro exigia adi√ß√£o manual de mais keywords, criando uma lista infinita e fr√°gil.

### A Solu√ß√£o (v4.5): LLM Router com Function Calling

Em vez de keywords, o sistema agora usa **GPT-4o-mini como classificador inteligente**. O LLM recebe as ferramentas dispon√≠veis (RPCs) como fun√ß√µes tipadas e **escolhe qual usar** com base na compreens√£o sem√¢ntica da pergunta:

```typescript
// ‚úÖ Abordagem nova (LLM Function Calling)
const completion = await openai.chat.completions.create({
    model: 'gpt-4o-mini',       // R√°pido (~500ms) e barato (~$0.001/chamada)
    temperature: 0,              // Determin√≠stico
    tools: availableTools,       // 7 ferramentas tipadas
    tool_choice: "required",     // Sempre escolhe uma
    messages: [
        { role: 'system', content: routerPrompt },
        { role: 'user', content: perguntaDoUsuario }
    ]
})
```

O LLM entende naturalmente que todas estas frases significam a mesma coisa:

- "quais propostas est√£o em aberto?"
- "me mostra as propostas que ainda n√£o foram aceitas"
- "tem algum or√ßamento pendente?"
- "quantos neg√≥cios n√£o fechamos ainda?"

‚Üí Todas mapeiam para: `query_all_proposals({ p_status_filter: "open" })`

---

## 1. Arquitetura do LLM Router

### Diagrama de Fluxo: Roteamento v4.5

```mermaid
flowchart TD
    A["üë§ Usu√°rio envia mensagem"] --> B{"üõ°Ô∏è Hard Gate?"}
    B -->|"Contrato/Cl√°usula/LGPD"| C["Agent_Contracts\n(STRICT_DOCS_ONLY)"]
    B -->|"Dados sens√≠veis/CPF"| D["Agent_GovernanceSecurity"]
    B -->|"N√£o"| E["üß† LLM Router\n(GPT-4o-mini + Function Calling)"]
    
    E --> F{"Tool escolhida?"}
    F -->|"query_all_proposals"| G["SQL Direto ‚Üí Propostas"]
    F -->|"query_all_clients"| H["SQL Direto ‚Üí Clientes"]
    F -->|"query_all_projects"| I["SQL Direto ‚Üí Projetos"]
    F -->|"query_all_tasks"| J["SQL Direto ‚Üí Tarefas"]
    F -->|"query_all_users"| K["SQL Direto ‚Üí Usu√°rios"]
    F -->|"query_access_summary"| L["SQL Direto ‚Üí Acessos"]
    F -->|"rag_search"| M["RAG Sem√¢ntico"]
    F -->|"Falha/Erro"| N["‚ö° Heur√≠stica Fallback"]
    
    G & H & I & J & K & L & M & N --> O["üìù GPT-4o gera resposta\n(com hist√≥rico + identidade)"]

    style E fill:#4f46e5,stroke:#312e81,color:#fff
    style N fill:#f59e0b,stroke:#92400e,color:#000
    style C fill:#ef4444,stroke:#991b1b,color:#fff
    style D fill:#ef4444,stroke:#991b1b,color:#fff
```

### Hierarquia de Decis√£o (v4.1 ‚Üí v4.5)

```mermaid
flowchart LR
    subgraph "v4.1 (Antes)"
        A1["Hard Gate"] --> A2["Heur√≠stica\n(keywords)"]
        A2 -->|"confian√ßa < 0.78"| A3["LLM Fallback\n(classifica√ß√£o gen√©rica)"]
    end

    subgraph "v4.5 (Depois)"
        B1["Hard Gate"] --> B2["üß† LLM Router\n(Function Calling)"]
        B2 -->|"falha/erro"| B3["Heur√≠stica\nFallback"]
    end

    style A2 fill:#f59e0b,stroke:#92400e
    style A3 fill:#6b7280,stroke:#374151,color:#fff
    style B2 fill:#4f46e5,stroke:#312e81,color:#fff
    style B3 fill:#f59e0b,stroke:#92400e
```

**Invers√£o cr√≠tica**: Na v4.1, a heur√≠stica (keywords) era executada PRIMEIRO e o LLM era fallback. Na v4.5, o **LLM √© executado PRIMEIRO** e a heur√≠stica √© o fallback para resili√™ncia.

---

## 2. Ferramentas Tipadas (Function Definitions)

O LLM Router recebe 7 ferramentas com **schemas JSON tipados**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Ferramenta              ‚îÇ Par√¢metros                                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ query_all_proposals     ‚îÇ p_status_filter: "all" | "open" | "accepted"      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ query_all_clients       ‚îÇ p_status: "Ativo" | "Inativo" | "Suspenso" | ... ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ query_all_projects      ‚îÇ p_service_type: "traffic" | "website" | "lp"     ‚îÇ
‚îÇ                         ‚îÇ p_status_filter: "Ativo" | "Inativo"             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ query_all_tasks         ‚îÇ p_project_id: number (opcional)                   ‚îÇ
‚îÇ                         ‚îÇ p_status: "todo" | "in_progress" | "done" | ...  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ query_all_users         ‚îÇ (sem par√¢metros)                                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ query_access_summary    ‚îÇ (sem par√¢metros)                                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ rag_search              ‚îÇ (busca sem√¢ntica ‚Äî documentos e contratos)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Prompt do Router

O system prompt do LLM Router inclui **exemplos de mapeamento** para guiar a classifica√ß√£o:

```
"quais propostas est√£o em aberto?" ‚Üí query_all_proposals(p_status_filter: "open")
"quem s√£o nossos clientes ativos?" ‚Üí query_all_clients(p_status: "Ativo")
"liste todos os projetos de tr√°fego" ‚Üí query_all_projects(p_service_type: "traffic")
"quem acessou o sistema hoje?" ‚Üí query_access_summary()
"o que diz o contrato com a empresa X?" ‚Üí rag_search()
"tem alguma tarefa pendente?" ‚Üí query_all_tasks(p_status: "todo")
```

---

## 3. Gest√£o de Propostas: Open vs Accepted

### Problema Anterior

Todas as propostas apareciam em uma √∫nica lista. N√£o havia distin√ß√£o visual entre propostas pendentes e aceitas, nem no frontend nem nas consultas do agente.

### Solu√ß√£o v4.5

```mermaid
flowchart TD
    subgraph "Frontend ‚Äî Proposals.tsx"
        A["Carregar propostas + acceptances"] --> B{"proposal.id existe\nem acceptances?"}
        B -->|"N√£o"| C["üìã Tabela: Gerenciar Propostas\n(lista principal)"]
        B -->|"Sim"| D["‚úÖ Tabela: Propostas Aceitas\n(lista inferior)"]
    end

    subgraph "Backend ‚Äî query_all_proposals RPC"
        E["p_status_filter"] --> F{"Valor?"}
        F -->|"'open'"| G["WHERE NOT EXISTS\n(acceptances)"]
        F -->|"'accepted'"| H["WHERE EXISTS\n(acceptances)"]
        F -->|"'all'"| I["Sem filtro"]
    end

    subgraph "Aceite ‚Äî ProposalView.tsx"
        J["Usu√°rio clica 'Aceitar'"] --> K["INSERT INTO acceptances\nstatus: 'Inativo'"]
        K --> L["Proposta move de\nlista principal ‚Üí aceitas"]
    end

    style C fill:#3b82f6,stroke:#1e40af,color:#fff
    style D fill:#10b981,stroke:#065f46,color:#fff
    style K fill:#8b5cf6,stroke:#5b21b6,color:#fff
```

### Mudan√ßas por Arquivo

| Arquivo | Mudan√ßa |
|---------|---------|
| `ProposalView.tsx` | Aceite grava `status: 'Inativo'` na tabela `acceptances` |
| `Proposals.tsx` | Lista principal filtra `proposals.filter(p => !acceptances.some(...))` |
| `query_all_proposals` RPC | Novo par√¢metro `p_status_filter` ('all', 'open', 'accepted') |
| `router.ts` | LLM Router seleciona filtro correto via function calling |

### SQL: RPC query_all_proposals (v4.5)

```sql
CREATE OR REPLACE FUNCTION public.query_all_proposals(
  p_status_filter text DEFAULT 'all'
)
RETURNS json
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
BEGIN
  SELECT json_agg(p ORDER BY p.created_at DESC) INTO result
  FROM (
    SELECT p.*, 
      (SELECT count(*) FROM acceptances a WHERE a.proposal_id = p.id) > 0 AS was_accepted,
      (SELECT a.status FROM acceptances a WHERE a.proposal_id = p.id LIMIT 1) AS acceptance_status
    FROM proposals p
    WHERE
      (p_status_filter = 'all') OR
      (p_status_filter = 'open' AND NOT EXISTS (SELECT 1 FROM acceptances a WHERE a.proposal_id = p.id)) OR
      (p_status_filter = 'accepted' AND EXISTS (SELECT 1 FROM acceptances a WHERE a.proposal_id = p.id))
  ) p;
  RETURN COALESCE(result, '[]'::json);
END;
$$;
```

---

## 4. Limpeza de Par√¢metros RPC

### Problema Detectado

Quando o LLM omitia um par√¢metro opcional, o Function Calling √†s vezes enviava `null` ou `"null"` (string), causando erros silenciosos nas RPCs PostgreSQL.

### Solu√ß√£o: cleanParams

```typescript
const { rpc_name, ...rpcParams } = decision.db_query_params
// Limpar valores null/undefined/"null" antes de enviar ao PostgreSQL
const cleanParams: Record<string, any> = {}
for (const [k, v] of Object.entries(rpcParams)) {
    if (v !== null && v !== undefined && v !== 'null') cleanParams[k] = v
}
const { data, error } = await supabaseAdmin.rpc(rpc_name, cleanParams)
```

Isso garante que par√¢metros com `DEFAULT NULL` nas RPCs sejam tratados como NULL real no PostgreSQL.

### Mensagem de Resultado Vazio Melhorada

```typescript
// ‚ùå Antes (v4.1) ‚Äî GPT interpretava como "sem acesso"
contextText = 'Nenhum registro encontrado no banco de dados.'

// ‚úÖ Agora (v4.5) ‚Äî GPT entende que consultou mas n√£o achou
contextText = `CONSULTA REALIZADA COM SUCESSO via ${rpc_name}, 
mas NENHUM registro foi encontrado. Informe ao usu√°rio que a consulta 
foi feita no banco de dados e n√£o h√° registros correspondentes no momento.`
```

---

## 5. Fluxo Completo (v4.5)

```mermaid
sequenceDiagram
    actor User as üë§ Usu√°rio
    participant FE as Frontend
    participant CB as chat-brain
    participant LLM_R as üß† GPT-4o-mini<br/>(Router)
    participant DB as PostgreSQL
    participant LLM_G as üìù GPT-4o<br/>(Gera√ß√£o)

    User->>FE: "quais propostas est√£o em aberto?"
    FE->>CB: POST /chat-brain (query + JWT + session_id)
    
    Note over CB: 1. Identidade
    CB->>DB: auth.getUser() ‚Üí email ‚Üí app_users
    DB-->>CB: { nome: "Andr√©", cargo: "gestor" }
    
    Note over CB: 2. Mem√≥ria
    CB->>DB: get_session_history(session_id, 20)
    DB-->>CB: [√∫ltimas 20 mensagens]
    
    Note over CB: 3. LLM Router (Function Calling)
    CB->>LLM_R: tools: [7 RPCs] + mensagem do usu√°rio
    LLM_R-->>CB: query_all_proposals({ p_status_filter: "open" })
    
    Note over CB: 4. Execu√ß√£o SQL
    CB->>DB: supabaseAdmin.rpc('query_all_proposals', { p_status_filter: 'open' })
    DB-->>CB: JSON com 6 propostas em aberto
    
    Note over CB: 5. Gera√ß√£o
    CB->>LLM_G: system + identidade + dados SQL + hist√≥rico + pergunta
    LLM_G-->>CB: "Andr√©, existem 6 propostas em aberto: ..."
    
    CB-->>FE: resposta formatada
    FE-->>User: Exibe resposta na interface
```

---

## 6. Comparativo Completo v1 ‚Üí v4.5

| Dimens√£o | v1 | v2 | v3 | v4.1 | **v4.5** |
|----------|----|----|----|----- |----------|
| **Roteamento** | Nenhum | Keywords | Keywords + filtros | Keywords + LLM fallback | **üß† LLM-first (Function Calling)** |
| **Identidade** | ‚ùå | ‚ùå | ‚ùå | ‚úÖ Nome + Cargo | ‚úÖ Nome + Cargo |
| **Mem√≥ria** | ‚ùå | ‚ùå | ‚ùå | ‚úÖ 20 msgs/sess√£o | ‚úÖ 20 msgs/sess√£o |
| **Recupera√ß√£o** | RAG puro | RAG + filtros | RAG + SQL | RAG + SQL + 6 RPCs | RAG + SQL + **7 RPCs tipadas** |
| **Propostas** | ‚Äî | ‚Äî | Lista √∫nica | Lista √∫nica | **Open vs Accepted** |
| **Robustez NLP** | ‚Äî | Fr√°gil | Fr√°gil | Fr√°gil (keywords) | **‚úÖ Sem√¢ntico (LLM)** |
| **Custo Router** | $0 | $0 | $0 | ~$0.03/chamada (GPT-4o) | **~$0.001/chamada (4o-mini)** |
| **Lat√™ncia Router** | 0ms | 0ms | 0ms | ~2s (GPT-4o) | **~500ms (4o-mini)** |
| **Anti-alucina√ß√£o** | Filtro tipo | Pol√≠ticas | + SQL factual | + contexto real | + **resultado vazio expl√≠cito** |

---

## 7. Especifica√ß√µes T√©cnicas

- **Modelo de Gera√ß√£o**: GPT-4o (OpenAI)
- **Modelo de Roteamento**: GPT-4o-mini (Function Calling, temperature: 0)
- **Modelo de Embedding**: `text-embedding-3-small` (1536 dimens√µes)
- **Banco de Dados**: PostgreSQL 15 com `pgvector` + `pg_cron`
- **Infraestrutura**: Supabase Edge Functions (Deno)
- **RPCs**: 7 fun√ß√µes SQL (`query_all_projects`, `query_all_clients`, `query_all_proposals`, `query_all_users`, `query_all_tasks`, `query_access_summary`, `get_session_history`)
- **Contexto Multi-Turn**: √öltimas 20 mensagens por sess√£o (~8.000 tokens)
- **Tabelas Cobertas**: 16 tabelas do schema `public` + 2 do schema `brain`
- **Custo estimado por consulta**: ~$0.004 (Router: $0.001 + Gera√ß√£o: $0.003)

---

## 8. Custo e Performance

### Comparativo de Custo do Router

| Vers√£o | Modelo Router | Custo/chamada | Lat√™ncia | Robustez |
|--------|--------------|---------------|----------|----------|
| v2‚Äìv4.1 | Heur√≠stica (keywords) | $0 | ~0ms | ‚ùå Fr√°gil |
| v4.1 (fallback) | GPT-4o (JSON) | ~$0.03 | ~2.000ms | ‚ö†Ô∏è M√©dio |
| **v4.5** | **GPT-4o-mini (FC)** | **~$0.001** | **~500ms** | **‚úÖ Robusto** |

### Estimativa de Custo Mensal

Considerando ~500 consultas/m√™s ao agente:

- **Router (GPT-4o-mini)**: 500 √ó $0.001 = **$0.50/m√™s**
- **Gera√ß√£o (GPT-4o)**: 500 √ó $0.003 = **$1.50/m√™s**
- **Total estimado**: **~$2.00/m√™s**

---

## 9. Resili√™ncia: Tr√™s Camadas de Prote√ß√£o

```mermaid
flowchart TD
    A["Mensagem do usu√°rio"] --> B["Camada 1: Hard Gates\n(determin√≠stico, sem LLM)"]
    B -->|"Match"| C["‚úÖ Decis√£o imediata"]
    B -->|"N√£o"| D["Camada 2: LLM Router\n(GPT-4o-mini, Function Calling)"]
    D -->|"Sucesso"| E["‚úÖ Tool + par√¢metros escolhidos"]
    D -->|"Erro/Timeout"| F["Camada 3: Heur√≠stica Fallback\n(keywords est√°ticas)"]
    F --> G["‚úÖ Melhor esfor√ßo"]
    
    C --> H["Execu√ß√£o (SQL ou RAG)"]
    E --> H
    G --> H
    H --> I["GPT-4o gera resposta final"]

    style B fill:#ef4444,stroke:#991b1b,color:#fff
    style D fill:#4f46e5,stroke:#312e81,color:#fff
    style F fill:#f59e0b,stroke:#92400e,color:#000
```

| Camada | Quando ativa | Lat√™ncia | Exemplo |
|--------|-------------|----------|---------|
| **Hard Gate** | Contratos, dados sens√≠veis | 0ms | "qual a cl√°usula de rescis√£o?" |
| **LLM Router** | 95% das perguntas | ~500ms | "tem proposta pendente?" |
| **Heur√≠stica** | LLM falha ou timeout | 0ms | Fallback de seguran√ßa |

---

## 10. Impacto Pr√°tico

### Antes (v4.1) ‚Äî Falha por keyword faltando

```
Usu√°rio: "quais propostas est√£o em aberto?"
Router:  ‚ùå "quais" n√£o era keyword ‚Üí caiu no RAG gen√©rico
Agente:  Retornou 3 propostas erradas (incluindo aceitas)

Usu√°rio: "tem alguma tarefa pendente?"
Router:  ‚ùå "pendente" n√£o era keyword de listagem
Agente:  "N√£o tenho acesso ao sistema de tarefas" (alucina√ß√£o)
```

### Depois (v4.5) ‚Äî Compreens√£o sem√¢ntica

```
Usu√°rio: "quais propostas est√£o em aberto?"
LLM:     ‚úÖ query_all_proposals(p_status_filter: "open")
Agente:  Retornou as 6 propostas corretas em aberto

Usu√°rio: "tem alguma tarefa pendente?"
LLM:     ‚úÖ query_all_tasks(p_status: "todo")
Agente:  "Andr√©, n√£o h√° tarefas pendentes no momento." (resultado real)

Usu√°rio: "me mostra os clientes que est√£o inativos"
LLM:     ‚úÖ query_all_clients(p_status: "Inativo")
Agente:  Retornou lista precisa de clientes inativos
```

---

## 11. Arquivos Modificados

| Arquivo | Tipo | Mudan√ßa |
|---------|------|---------|
| `supabase/functions/chat-brain/index.ts` | Backend | LLM Router com Function Calling (GPT-4o-mini), cleanup de params, mensagem de vazio melhorada |
| `supabase/functions/_shared/agents/router.ts` | Backend | Prioridade invertida (LLM-first, heur√≠stica-fallback), keywords expandidas como backup |
| `pages/Proposals.tsx` | Frontend | Filtro visual: propostas aceitas separadas da lista principal |
| `pages/ProposalView.tsx` | Frontend | Status inicial de aceite definido como 'Inativo' |
| `supabase/migrations/20260217204000_update_proposals_rpc.sql` | Migra√ß√£o | RPC `query_all_proposals` com par√¢metro `p_status_filter` |

---

## Conclus√£o

A v4.5 marca a transi√ß√£o do Segundo C√©rebro de **sistema baseado em regras** para **sistema baseado em compreens√£o**. O roteamento por keywords era um ponto de falha silencioso ‚Äî o sistema parecia funcionar at√© encontrar uma varia√ß√£o lingu√≠stica n√£o prevista. Com o LLM Router:

1. **Qualquer forma de perguntar** √© compreendida ‚Äî sin√¥nimos, varia√ß√µes, contexto impl√≠cito
2. **Novos filtros** n√£o exigem c√≥digo ‚Äî basta adicionar par√¢metros na defini√ß√£o da tool
3. **Custo insignificante** ‚Äî ~$0.001 por classifica√ß√£o com GPT-4o-mini
4. **Zero manuten√ß√£o de keywords** ‚Äî o LLM aprende novas formas naturalmente

O pr√≥ximo passo natural √© expandir o cat√°logo de tools dispon√≠veis (ex: `query_financial_summary`, `create_task`, `update_project_status`), transformando o agente de **consultor passivo** em **executor de a√ß√µes** no sistema.
